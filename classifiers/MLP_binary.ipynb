{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker import get_execution_role\n",
    "from sklearn.model_selection import train_test_split\n",
    "from smote import smote_binary\n",
    "from skorch import NeuralNetClassifier\n",
    "from performance_report import performance_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup \n",
    "device = torch.device('cpu')\n",
    "bucket = 'm-team1'\n",
    "role = get_execution_role()    \n",
    "file = 'PD_remove_std_all_datasets.csv'\n",
    "data_loc = 's3://{}/{}'.format(bucket, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11627, 14])\n",
      "torch.Size([11627])\n"
     ]
    }
   ],
   "source": [
    "# reading CSV and separating data into train and test sets \n",
    "\n",
    "df = pd.read_csv(data_loc).iloc[: , 1:]\n",
    "\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "augment = True\n",
    "\n",
    "if augment:\n",
    "    df_train = pd.concat([y_train, X_train], axis=1)\n",
    "    df_train = smote_binary(df_train)\n",
    "    X_train = df_train.iloc[:,1:]\n",
    "    y_train = df_train.iloc[:,0]\n",
    "\n",
    "    X = torch.tensor(pd.concat([X_train, X_test]).values.astype(np.float32))\n",
    "    y = torch.tensor(pd.concat([y_train, y_test]).values.astype(np.long))\n",
    "    \n",
    "else:\n",
    "    X = torch.tensor(X.values.astype(np.float32))\n",
    "    y = torch.tensor(y.values.astype(np.long))   \n",
    "    \n",
    "print(X.size())\n",
    "print(y.size())\n",
    "    \n",
    "X_train = torch.tensor(X_train.values.astype(np.float32))\n",
    "X_test = torch.tensor(X_test.values.astype(np.float32))\n",
    "y_train = torch.tensor(y_train.values.astype(np.long))\n",
    "y_test = torch.tensor(y_test.values.astype(np.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim=14):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 32)\n",
    "        self.layer2 = nn.Linear(32, 64)\n",
    "        self.layer3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.softmax(self.layer3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5567\u001b[0m       \u001b[32m0.9451\u001b[0m        \u001b[35m0.4168\u001b[0m  0.1837\n",
      "      2        \u001b[36m0.3820\u001b[0m       \u001b[32m0.9524\u001b[0m        \u001b[35m0.3674\u001b[0m  0.1801\n",
      "      3        \u001b[36m0.3657\u001b[0m       \u001b[32m0.9558\u001b[0m        \u001b[35m0.3610\u001b[0m  0.1807\n",
      "      4        \u001b[36m0.3616\u001b[0m       \u001b[32m0.9578\u001b[0m        \u001b[35m0.3575\u001b[0m  0.1805\n",
      "      5        \u001b[36m0.3592\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.3556\u001b[0m  0.1803\n",
      "      6        \u001b[36m0.3578\u001b[0m       \u001b[32m0.9602\u001b[0m        \u001b[35m0.3542\u001b[0m  0.1805\n",
      "      7        \u001b[36m0.3556\u001b[0m       \u001b[32m0.9636\u001b[0m        \u001b[35m0.3525\u001b[0m  0.1917\n",
      "      8        \u001b[36m0.3542\u001b[0m       0.9626        0.3529  0.1806\n",
      "      9        \u001b[36m0.3532\u001b[0m       \u001b[32m0.9641\u001b[0m        \u001b[35m0.3517\u001b[0m  0.1930\n",
      "     10        \u001b[36m0.3525\u001b[0m       0.9641        \u001b[35m0.3509\u001b[0m  0.1803\n",
      "     11        \u001b[36m0.3517\u001b[0m       \u001b[32m0.9655\u001b[0m        \u001b[35m0.3502\u001b[0m  0.1803\n",
      "     12        \u001b[36m0.3513\u001b[0m       \u001b[32m0.9660\u001b[0m        \u001b[35m0.3491\u001b[0m  0.2142\n",
      "     13        \u001b[36m0.3507\u001b[0m       0.9631        0.3508  0.1824\n",
      "     14        \u001b[36m0.3502\u001b[0m       0.9650        \u001b[35m0.3486\u001b[0m  0.1812\n",
      "     15        \u001b[36m0.3501\u001b[0m       0.9660        \u001b[35m0.3483\u001b[0m  0.1804\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    Model,\n",
    "    max_epochs=15,\n",
    "    lr=0.001,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "net.fit(X_train, y_train)\n",
    "\n",
    "y_pred = net.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5092\u001b[0m       \u001b[32m0.9412\u001b[0m        \u001b[35m0.4015\u001b[0m  0.1661\n",
      "      2        \u001b[36m0.3808\u001b[0m       \u001b[32m0.9422\u001b[0m        \u001b[35m0.3744\u001b[0m  0.1675\n",
      "      3        \u001b[36m0.3704\u001b[0m       \u001b[32m0.9479\u001b[0m        \u001b[35m0.3688\u001b[0m  0.1684\n",
      "      4        \u001b[36m0.3674\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.3663\u001b[0m  0.1721\n",
      "      5        \u001b[36m0.3656\u001b[0m       0.9494        \u001b[35m0.3647\u001b[0m  0.1693\n",
      "      6        \u001b[36m0.3647\u001b[0m       \u001b[32m0.9510\u001b[0m        \u001b[35m0.3637\u001b[0m  0.1667\n",
      "      7        \u001b[36m0.3639\u001b[0m       0.9505        \u001b[35m0.3633\u001b[0m  0.1672\n",
      "      8        \u001b[36m0.3628\u001b[0m       \u001b[32m0.9520\u001b[0m        \u001b[35m0.3621\u001b[0m  0.1669\n",
      "      9        \u001b[36m0.3617\u001b[0m       0.9520        \u001b[35m0.3610\u001b[0m  0.1679\n",
      "     10        \u001b[36m0.3594\u001b[0m       \u001b[32m0.9551\u001b[0m        \u001b[35m0.3589\u001b[0m  0.1675\n",
      "     11        \u001b[36m0.3576\u001b[0m       0.9541        0.3600  0.1663\n",
      "     12        \u001b[36m0.3563\u001b[0m       0.9520        0.3591  0.1669\n",
      "     13        \u001b[36m0.3552\u001b[0m       \u001b[32m0.9587\u001b[0m        \u001b[35m0.3561\u001b[0m  0.1669\n",
      "     14        0.3554       0.9577        0.3562  0.1682\n",
      "     15        \u001b[36m0.3536\u001b[0m       \u001b[32m0.9598\u001b[0m        \u001b[35m0.3549\u001b[0m  0.1665\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5647\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.4155\u001b[0m  0.1658\n",
      "      2        \u001b[36m0.3839\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.3697\u001b[0m  0.1665\n",
      "      3        \u001b[36m0.3694\u001b[0m       \u001b[32m0.9525\u001b[0m        \u001b[35m0.3642\u001b[0m  0.1668\n",
      "      4        \u001b[36m0.3650\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.3616\u001b[0m  0.1663\n",
      "      5        \u001b[36m0.3626\u001b[0m       \u001b[32m0.9561\u001b[0m        \u001b[35m0.3597\u001b[0m  0.1661\n",
      "      6        \u001b[36m0.3601\u001b[0m       \u001b[32m0.9572\u001b[0m        \u001b[35m0.3581\u001b[0m  0.1667\n",
      "      7        \u001b[36m0.3588\u001b[0m       0.9561        \u001b[35m0.3574\u001b[0m  0.1671\n",
      "      8        \u001b[36m0.3573\u001b[0m       \u001b[32m0.9582\u001b[0m        \u001b[35m0.3553\u001b[0m  0.1667\n",
      "      9        \u001b[36m0.3561\u001b[0m       \u001b[32m0.9623\u001b[0m        \u001b[35m0.3550\u001b[0m  0.1666\n",
      "     10        \u001b[36m0.3552\u001b[0m       0.9608        \u001b[35m0.3537\u001b[0m  0.1660\n",
      "     11        \u001b[36m0.3547\u001b[0m       0.9623        \u001b[35m0.3529\u001b[0m  0.1662\n",
      "     12        \u001b[36m0.3536\u001b[0m       \u001b[32m0.9628\u001b[0m        \u001b[35m0.3526\u001b[0m  0.1668\n",
      "     13        0.3537       0.9623        \u001b[35m0.3518\u001b[0m  0.1666\n",
      "     14        \u001b[36m0.3532\u001b[0m       0.9608        0.3542  0.1656\n",
      "     15        \u001b[36m0.3525\u001b[0m       \u001b[32m0.9649\u001b[0m        \u001b[35m0.3507\u001b[0m  0.1675\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5475\u001b[0m       \u001b[32m0.9458\u001b[0m        \u001b[35m0.4179\u001b[0m  0.1666\n",
      "      2        \u001b[36m0.3841\u001b[0m       \u001b[32m0.9469\u001b[0m        \u001b[35m0.3706\u001b[0m  0.1666\n",
      "      3        \u001b[36m0.3693\u001b[0m       \u001b[32m0.9520\u001b[0m        \u001b[35m0.3637\u001b[0m  0.1665\n",
      "      4        \u001b[36m0.3652\u001b[0m       \u001b[32m0.9561\u001b[0m        \u001b[35m0.3604\u001b[0m  0.1664\n",
      "      5        \u001b[36m0.3626\u001b[0m       \u001b[32m0.9577\u001b[0m        \u001b[35m0.3583\u001b[0m  0.1666\n",
      "      6        \u001b[36m0.3599\u001b[0m       \u001b[32m0.9582\u001b[0m        \u001b[35m0.3562\u001b[0m  0.1667\n",
      "      7        \u001b[36m0.3579\u001b[0m       \u001b[32m0.9603\u001b[0m        \u001b[35m0.3548\u001b[0m  0.1668\n",
      "      8        \u001b[36m0.3565\u001b[0m       0.9603        \u001b[35m0.3536\u001b[0m  0.1664\n",
      "      9        \u001b[36m0.3560\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.3528\u001b[0m  0.1665\n",
      "     10        \u001b[36m0.3552\u001b[0m       \u001b[32m0.9613\u001b[0m        0.3529  0.1663\n",
      "     11        0.3554       0.9608        \u001b[35m0.3516\u001b[0m  0.1669\n",
      "     12        \u001b[36m0.3540\u001b[0m       \u001b[32m0.9639\u001b[0m        \u001b[35m0.3509\u001b[0m  0.1668\n",
      "     13        \u001b[36m0.3537\u001b[0m       \u001b[32m0.9654\u001b[0m        \u001b[35m0.3506\u001b[0m  0.1673\n",
      "     14        \u001b[36m0.3530\u001b[0m       0.9623        \u001b[35m0.3504\u001b[0m  0.1682\n",
      "     15        \u001b[36m0.3526\u001b[0m       0.9628        0.3522  0.1659\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5449\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m0.4093\u001b[0m  0.1659\n",
      "      2        \u001b[36m0.3812\u001b[0m       \u001b[32m0.9453\u001b[0m        \u001b[35m0.3720\u001b[0m  0.1664\n",
      "      3        \u001b[36m0.3685\u001b[0m       \u001b[32m0.9499\u001b[0m        \u001b[35m0.3664\u001b[0m  0.1669\n",
      "      4        \u001b[36m0.3644\u001b[0m       \u001b[32m0.9525\u001b[0m        \u001b[35m0.3629\u001b[0m  0.1658\n",
      "      5        \u001b[36m0.3617\u001b[0m       \u001b[32m0.9536\u001b[0m        0.3633  0.1708\n",
      "      6        \u001b[36m0.3596\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.3598\u001b[0m  0.1670\n",
      "      7        \u001b[36m0.3572\u001b[0m       \u001b[32m0.9567\u001b[0m        \u001b[35m0.3576\u001b[0m  0.1667\n",
      "      8        \u001b[36m0.3558\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.3565\u001b[0m  0.1666\n",
      "      9        \u001b[36m0.3550\u001b[0m       0.9551        0.3576  0.1659\n",
      "     10        \u001b[36m0.3539\u001b[0m       0.9577        \u001b[35m0.3555\u001b[0m  0.1665\n",
      "     11        \u001b[36m0.3538\u001b[0m       0.9587        \u001b[35m0.3550\u001b[0m  0.1661\n",
      "     12        \u001b[36m0.3532\u001b[0m       \u001b[32m0.9613\u001b[0m        \u001b[35m0.3540\u001b[0m  0.1661\n",
      "     13        \u001b[36m0.3523\u001b[0m       0.9608        0.3543  0.1686\n",
      "     14        \u001b[36m0.3518\u001b[0m       0.9598        \u001b[35m0.3540\u001b[0m  0.1671\n",
      "     15        \u001b[36m0.3515\u001b[0m       0.9603        0.3545  0.1672\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5344\u001b[0m       \u001b[32m0.9370\u001b[0m        \u001b[35m0.4131\u001b[0m  0.1668\n",
      "      2        \u001b[36m0.3848\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m0.3775\u001b[0m  0.1675\n",
      "      3        \u001b[36m0.3724\u001b[0m       \u001b[32m0.9432\u001b[0m        \u001b[35m0.3711\u001b[0m  0.1666\n",
      "      4        \u001b[36m0.3685\u001b[0m       \u001b[32m0.9479\u001b[0m        \u001b[35m0.3681\u001b[0m  0.1664\n",
      "      5        \u001b[36m0.3663\u001b[0m       0.9479        \u001b[35m0.3663\u001b[0m  0.1671\n",
      "      6        \u001b[36m0.3647\u001b[0m       \u001b[32m0.9499\u001b[0m        \u001b[35m0.3644\u001b[0m  0.1682\n",
      "      7        \u001b[36m0.3629\u001b[0m       \u001b[32m0.9510\u001b[0m        \u001b[35m0.3627\u001b[0m  0.1677\n",
      "      8        \u001b[36m0.3606\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.3597\u001b[0m  0.1672\n",
      "      9        \u001b[36m0.3587\u001b[0m       0.9541        \u001b[35m0.3592\u001b[0m  0.1667\n",
      "     10        \u001b[36m0.3577\u001b[0m       \u001b[32m0.9567\u001b[0m        \u001b[35m0.3575\u001b[0m  0.1665\n",
      "     11        \u001b[36m0.3567\u001b[0m       \u001b[32m0.9582\u001b[0m        \u001b[35m0.3568\u001b[0m  0.1664\n",
      "     12        \u001b[36m0.3558\u001b[0m       0.9567        \u001b[35m0.3567\u001b[0m  0.1658\n",
      "     13        \u001b[36m0.3555\u001b[0m       \u001b[32m0.9598\u001b[0m        \u001b[35m0.3556\u001b[0m  0.1666\n",
      "     14        \u001b[36m0.3550\u001b[0m       \u001b[32m0.9603\u001b[0m        \u001b[35m0.3550\u001b[0m  0.1668\n",
      "     15        \u001b[36m0.3541\u001b[0m       0.9587        0.3553  0.1658\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5523\u001b[0m       \u001b[32m0.9438\u001b[0m        \u001b[35m0.4110\u001b[0m  0.1661\n",
      "      2        \u001b[36m0.3848\u001b[0m       \u001b[32m0.9458\u001b[0m        \u001b[35m0.3711\u001b[0m  0.1669\n",
      "      3        \u001b[36m0.3721\u001b[0m       \u001b[32m0.9515\u001b[0m        \u001b[35m0.3646\u001b[0m  0.1659\n",
      "      4        \u001b[36m0.3674\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.3602\u001b[0m  0.2034\n",
      "      5        \u001b[36m0.3631\u001b[0m       \u001b[32m0.9572\u001b[0m        \u001b[35m0.3585\u001b[0m  0.1825\n",
      "      6        \u001b[36m0.3601\u001b[0m       \u001b[32m0.9598\u001b[0m        \u001b[35m0.3566\u001b[0m  0.1673\n",
      "      7        \u001b[36m0.3589\u001b[0m       0.9592        \u001b[35m0.3559\u001b[0m  0.1672\n",
      "      8        \u001b[36m0.3576\u001b[0m       \u001b[32m0.9603\u001b[0m        \u001b[35m0.3538\u001b[0m  0.1666\n",
      "      9        \u001b[36m0.3572\u001b[0m       \u001b[32m0.9613\u001b[0m        \u001b[35m0.3532\u001b[0m  0.1667\n",
      "     10        \u001b[36m0.3562\u001b[0m       0.9608        \u001b[35m0.3524\u001b[0m  0.1672\n",
      "     11        \u001b[36m0.3561\u001b[0m       \u001b[32m0.9618\u001b[0m        \u001b[35m0.3522\u001b[0m  0.1680\n",
      "     12        \u001b[36m0.3556\u001b[0m       0.9608        \u001b[35m0.3518\u001b[0m  0.1674\n",
      "     13        \u001b[36m0.3549\u001b[0m       0.9613        \u001b[35m0.3518\u001b[0m  0.1665\n",
      "     14        \u001b[36m0.3542\u001b[0m       \u001b[32m0.9639\u001b[0m        0.3520  0.1670\n",
      "     15        \u001b[36m0.3538\u001b[0m       \u001b[32m0.9654\u001b[0m        \u001b[35m0.3501\u001b[0m  0.1664\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5583\u001b[0m       \u001b[32m0.9438\u001b[0m        \u001b[35m0.4188\u001b[0m  0.1702\n",
      "      2        \u001b[36m0.3873\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.3690\u001b[0m  0.1669\n",
      "      3        \u001b[36m0.3699\u001b[0m       \u001b[32m0.9536\u001b[0m        \u001b[35m0.3626\u001b[0m  0.1671\n",
      "      4        \u001b[36m0.3642\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.3578\u001b[0m  0.1668\n",
      "      5        \u001b[36m0.3602\u001b[0m       \u001b[32m0.9603\u001b[0m        \u001b[35m0.3562\u001b[0m  0.1664\n",
      "      6        \u001b[36m0.3583\u001b[0m       0.9592        0.3573  0.1668\n",
      "      7        \u001b[36m0.3568\u001b[0m       0.9592        \u001b[35m0.3539\u001b[0m  0.1671\n",
      "      8        \u001b[36m0.3555\u001b[0m       0.9598        \u001b[35m0.3530\u001b[0m  0.1666\n",
      "      9        \u001b[36m0.3544\u001b[0m       0.9598        0.3537  0.1679\n",
      "     10        \u001b[36m0.3540\u001b[0m       \u001b[32m0.9628\u001b[0m        \u001b[35m0.3523\u001b[0m  0.1670\n",
      "     11        \u001b[36m0.3532\u001b[0m       \u001b[32m0.9639\u001b[0m        \u001b[35m0.3513\u001b[0m  0.1665\n",
      "     12        \u001b[36m0.3526\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.3512\u001b[0m  0.1688\n",
      "     13        \u001b[36m0.3524\u001b[0m       0.9644        \u001b[35m0.3506\u001b[0m  0.1685\n",
      "     14        \u001b[36m0.3517\u001b[0m       \u001b[32m0.9654\u001b[0m        \u001b[35m0.3497\u001b[0m  0.1689\n",
      "     15        0.3518       0.9644        0.3500  0.1674\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5630\u001b[0m       \u001b[32m0.9401\u001b[0m        \u001b[35m0.4214\u001b[0m  0.1650\n",
      "      2        \u001b[36m0.3854\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.3726\u001b[0m  0.1656\n",
      "      3        \u001b[36m0.3703\u001b[0m       \u001b[32m0.9484\u001b[0m        \u001b[35m0.3676\u001b[0m  0.1664\n",
      "      4        \u001b[36m0.3671\u001b[0m       \u001b[32m0.9515\u001b[0m        \u001b[35m0.3640\u001b[0m  0.1655\n",
      "      5        \u001b[36m0.3646\u001b[0m       \u001b[32m0.9536\u001b[0m        \u001b[35m0.3618\u001b[0m  0.1655\n",
      "      6        \u001b[36m0.3630\u001b[0m       \u001b[32m0.9551\u001b[0m        \u001b[35m0.3613\u001b[0m  0.1657\n",
      "      7        \u001b[36m0.3605\u001b[0m       0.9551        \u001b[35m0.3600\u001b[0m  0.1659\n",
      "      8        \u001b[36m0.3594\u001b[0m       0.9546        \u001b[35m0.3599\u001b[0m  0.1662\n",
      "      9        \u001b[36m0.3591\u001b[0m       \u001b[32m0.9567\u001b[0m        \u001b[35m0.3578\u001b[0m  0.1669\n",
      "     10        \u001b[36m0.3578\u001b[0m       \u001b[32m0.9572\u001b[0m        \u001b[35m0.3571\u001b[0m  0.1663\n",
      "     11        \u001b[36m0.3573\u001b[0m       0.9561        0.3574  0.1661\n",
      "     12        \u001b[36m0.3566\u001b[0m       \u001b[32m0.9582\u001b[0m        \u001b[35m0.3555\u001b[0m  0.1712\n",
      "     13        \u001b[36m0.3558\u001b[0m       0.9567        0.3570  0.2006\n",
      "     14        \u001b[36m0.3551\u001b[0m       \u001b[32m0.9598\u001b[0m        \u001b[35m0.3547\u001b[0m  0.1811\n",
      "     15        \u001b[36m0.3549\u001b[0m       0.9582        0.3552  0.1667\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5682\u001b[0m       \u001b[32m0.9412\u001b[0m        \u001b[35m0.4213\u001b[0m  0.1658\n",
      "      2        \u001b[36m0.3864\u001b[0m       \u001b[32m0.9438\u001b[0m        \u001b[35m0.3744\u001b[0m  0.1662\n",
      "      3        \u001b[36m0.3720\u001b[0m       \u001b[32m0.9463\u001b[0m        \u001b[35m0.3681\u001b[0m  0.1672\n",
      "      4        \u001b[36m0.3677\u001b[0m       \u001b[32m0.9520\u001b[0m        \u001b[35m0.3652\u001b[0m  0.1724\n",
      "      5        \u001b[36m0.3651\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.3617\u001b[0m  0.1658\n",
      "      6        \u001b[36m0.3637\u001b[0m       \u001b[32m0.9561\u001b[0m        \u001b[35m0.3599\u001b[0m  0.1666\n",
      "      7        \u001b[36m0.3614\u001b[0m       \u001b[32m0.9572\u001b[0m        \u001b[35m0.3590\u001b[0m  0.1662\n",
      "      8        \u001b[36m0.3598\u001b[0m       \u001b[32m0.9577\u001b[0m        \u001b[35m0.3575\u001b[0m  0.1669\n",
      "      9        \u001b[36m0.3581\u001b[0m       \u001b[32m0.9582\u001b[0m        \u001b[35m0.3563\u001b[0m  0.1671\n",
      "     10        \u001b[36m0.3568\u001b[0m       0.9577        0.3565  0.1661\n",
      "     11        \u001b[36m0.3564\u001b[0m       \u001b[32m0.9587\u001b[0m        \u001b[35m0.3555\u001b[0m  0.1660\n",
      "     12        \u001b[36m0.3552\u001b[0m       \u001b[32m0.9603\u001b[0m        \u001b[35m0.3533\u001b[0m  0.1669\n",
      "     13        \u001b[36m0.3543\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.3529\u001b[0m  0.1659\n",
      "     14        \u001b[36m0.3538\u001b[0m       0.9577        0.3554  0.1663\n",
      "     15        \u001b[36m0.3534\u001b[0m       \u001b[32m0.9613\u001b[0m        \u001b[35m0.3523\u001b[0m  0.1665\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5757\u001b[0m       \u001b[32m0.9355\u001b[0m        \u001b[35m0.4307\u001b[0m  0.1658\n",
      "      2        \u001b[36m0.3899\u001b[0m       \u001b[32m0.9407\u001b[0m        \u001b[35m0.3771\u001b[0m  0.1663\n",
      "      3        \u001b[36m0.3733\u001b[0m       \u001b[32m0.9438\u001b[0m        \u001b[35m0.3706\u001b[0m  0.1666\n",
      "      4        \u001b[36m0.3686\u001b[0m       \u001b[32m0.9515\u001b[0m        \u001b[35m0.3659\u001b[0m  0.1653\n",
      "      5        \u001b[36m0.3652\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.3629\u001b[0m  0.1664\n",
      "      6        \u001b[36m0.3628\u001b[0m       0.9536        \u001b[35m0.3628\u001b[0m  0.1659\n",
      "      7        \u001b[36m0.3611\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.3593\u001b[0m  0.1659\n",
      "      8        \u001b[36m0.3592\u001b[0m       \u001b[32m0.9577\u001b[0m        \u001b[35m0.3582\u001b[0m  0.1664\n",
      "      9        \u001b[36m0.3586\u001b[0m       0.9556        0.3586  0.1668\n",
      "     10        \u001b[36m0.3578\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.3559\u001b[0m  0.1661\n",
      "     11        \u001b[36m0.3566\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.3549\u001b[0m  0.1662\n",
      "     12        \u001b[36m0.3564\u001b[0m       \u001b[32m0.9618\u001b[0m        \u001b[35m0.3542\u001b[0m  0.1659\n",
      "     13        \u001b[36m0.3555\u001b[0m       0.9608        \u001b[35m0.3537\u001b[0m  0.1662\n",
      "     14        \u001b[36m0.3545\u001b[0m       0.9608        \u001b[35m0.3532\u001b[0m  0.1678\n",
      "     15        \u001b[36m0.3545\u001b[0m       0.9613        0.3533  0.1680\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5726\u001b[0m       \u001b[32m0.9360\u001b[0m        \u001b[35m0.4243\u001b[0m  0.1669\n",
      "      2        \u001b[36m0.3861\u001b[0m       \u001b[32m0.9463\u001b[0m        \u001b[35m0.3727\u001b[0m  0.1670\n",
      "      3        \u001b[36m0.3701\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.3662\u001b[0m  0.1678\n",
      "      4        \u001b[36m0.3658\u001b[0m       \u001b[32m0.9530\u001b[0m        \u001b[35m0.3620\u001b[0m  0.1910\n",
      "      5        \u001b[36m0.3632\u001b[0m       \u001b[32m0.9551\u001b[0m        \u001b[35m0.3599\u001b[0m  0.1674\n",
      "      6        \u001b[36m0.3610\u001b[0m       \u001b[32m0.9561\u001b[0m        \u001b[35m0.3595\u001b[0m  0.1662\n",
      "      7        \u001b[36m0.3587\u001b[0m       0.9541        0.3597  0.1671\n",
      "      8        \u001b[36m0.3575\u001b[0m       0.9541        \u001b[35m0.3588\u001b[0m  0.1673\n",
      "      9        \u001b[36m0.3562\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.3552\u001b[0m  0.1895\n",
      "     10        \u001b[36m0.3553\u001b[0m       \u001b[32m0.9613\u001b[0m        \u001b[35m0.3545\u001b[0m  0.2318\n",
      "     11        \u001b[36m0.3550\u001b[0m       0.9598        0.3549  0.1702\n",
      "     12        \u001b[36m0.3545\u001b[0m       0.9613        \u001b[35m0.3534\u001b[0m  0.2024\n",
      "     13        \u001b[36m0.3536\u001b[0m       0.9613        \u001b[35m0.3529\u001b[0m  0.1755\n",
      "     14        \u001b[36m0.3530\u001b[0m       0.9561        0.3566  0.1669\n",
      "     15        0.3531       0.9613        \u001b[35m0.3528\u001b[0m  0.1665\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5862\u001b[0m       \u001b[32m0.9422\u001b[0m        \u001b[35m0.4303\u001b[0m  0.1660\n",
      "      2        \u001b[36m0.3857\u001b[0m       \u001b[32m0.9453\u001b[0m        \u001b[35m0.3727\u001b[0m  0.1721\n",
      "      3        \u001b[36m0.3683\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.3675\u001b[0m  0.1697\n",
      "      4        \u001b[36m0.3651\u001b[0m       \u001b[32m0.9499\u001b[0m        \u001b[35m0.3654\u001b[0m  0.1663\n",
      "      5        \u001b[36m0.3635\u001b[0m       \u001b[32m0.9515\u001b[0m        \u001b[35m0.3632\u001b[0m  0.1658\n",
      "      6        \u001b[36m0.3614\u001b[0m       \u001b[32m0.9525\u001b[0m        \u001b[35m0.3611\u001b[0m  0.1683\n",
      "      7        \u001b[36m0.3589\u001b[0m       \u001b[32m0.9536\u001b[0m        \u001b[35m0.3599\u001b[0m  0.1671\n",
      "      8        \u001b[36m0.3574\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.3582\u001b[0m  0.1673\n",
      "      9        \u001b[36m0.3564\u001b[0m       \u001b[32m0.9561\u001b[0m        \u001b[35m0.3575\u001b[0m  0.1671\n",
      "     10        \u001b[36m0.3551\u001b[0m       0.9561        \u001b[35m0.3564\u001b[0m  0.1665\n",
      "     11        \u001b[36m0.3546\u001b[0m       \u001b[32m0.9572\u001b[0m        \u001b[35m0.3553\u001b[0m  0.1663\n",
      "     12        \u001b[36m0.3538\u001b[0m       \u001b[32m0.9582\u001b[0m        \u001b[35m0.3544\u001b[0m  0.1666\n",
      "     13        \u001b[36m0.3522\u001b[0m       \u001b[32m0.9598\u001b[0m        \u001b[35m0.3544\u001b[0m  0.1672\n",
      "     14        0.3524       \u001b[32m0.9603\u001b[0m        \u001b[35m0.3536\u001b[0m  0.1667\n",
      "     15        \u001b[36m0.3513\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.3529\u001b[0m  0.1665\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5480\u001b[0m       \u001b[32m0.9340\u001b[0m        \u001b[35m0.4102\u001b[0m  0.1653\n",
      "      2        \u001b[36m0.3838\u001b[0m       \u001b[32m0.9443\u001b[0m        \u001b[35m0.3746\u001b[0m  0.1671\n",
      "      3        \u001b[36m0.3715\u001b[0m       \u001b[32m0.9499\u001b[0m        \u001b[35m0.3675\u001b[0m  0.1764\n",
      "      4        \u001b[36m0.3674\u001b[0m       \u001b[32m0.9536\u001b[0m        \u001b[35m0.3632\u001b[0m  0.1676\n",
      "      5        \u001b[36m0.3648\u001b[0m       \u001b[32m0.9541\u001b[0m        \u001b[35m0.3622\u001b[0m  0.1669\n",
      "      6        \u001b[36m0.3632\u001b[0m       \u001b[32m0.9567\u001b[0m        \u001b[35m0.3586\u001b[0m  0.1663\n",
      "      7        \u001b[36m0.3613\u001b[0m       \u001b[32m0.9572\u001b[0m        \u001b[35m0.3572\u001b[0m  0.1662\n",
      "      8        \u001b[36m0.3598\u001b[0m       0.9556        0.3587  0.1662\n",
      "      9        \u001b[36m0.3584\u001b[0m       0.9572        0.3577  0.1667\n",
      "     10        \u001b[36m0.3568\u001b[0m       \u001b[32m0.9603\u001b[0m        \u001b[35m0.3539\u001b[0m  0.1661\n",
      "     11        \u001b[36m0.3555\u001b[0m       \u001b[32m0.9623\u001b[0m        \u001b[35m0.3527\u001b[0m  0.1658\n",
      "     12        \u001b[36m0.3546\u001b[0m       \u001b[32m0.9634\u001b[0m        \u001b[35m0.3523\u001b[0m  0.1688\n",
      "     13        \u001b[36m0.3545\u001b[0m       0.9634        \u001b[35m0.3514\u001b[0m  0.2022\n",
      "     14        \u001b[36m0.3535\u001b[0m       \u001b[32m0.9649\u001b[0m        \u001b[35m0.3510\u001b[0m  0.1797\n",
      "     15        \u001b[36m0.3532\u001b[0m       0.9639        0.3514  0.1671\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5610\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m0.4170\u001b[0m  0.1656\n",
      "      2        \u001b[36m0.3837\u001b[0m       \u001b[32m0.9469\u001b[0m        \u001b[35m0.3724\u001b[0m  0.1674\n",
      "      3        \u001b[36m0.3695\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.3672\u001b[0m  0.1665\n",
      "      4        \u001b[36m0.3655\u001b[0m       \u001b[32m0.9520\u001b[0m        \u001b[35m0.3634\u001b[0m  0.1675\n",
      "      5        \u001b[36m0.3625\u001b[0m       \u001b[32m0.9536\u001b[0m        \u001b[35m0.3608\u001b[0m  0.1673\n",
      "      6        \u001b[36m0.3605\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.3591\u001b[0m  0.1671\n",
      "      7        \u001b[36m0.3588\u001b[0m       \u001b[32m0.9572\u001b[0m        \u001b[35m0.3582\u001b[0m  0.1681\n",
      "      8        \u001b[36m0.3577\u001b[0m       0.9561        \u001b[35m0.3569\u001b[0m  0.1668\n",
      "      9        \u001b[36m0.3567\u001b[0m       \u001b[32m0.9587\u001b[0m        \u001b[35m0.3559\u001b[0m  0.1664\n",
      "     10        \u001b[36m0.3560\u001b[0m       0.9561        0.3582  0.1671\n",
      "     11        \u001b[36m0.3549\u001b[0m       0.9587        \u001b[35m0.3553\u001b[0m  0.1666\n",
      "     12        \u001b[36m0.3549\u001b[0m       \u001b[32m0.9603\u001b[0m        \u001b[35m0.3546\u001b[0m  0.1662\n",
      "     13        \u001b[36m0.3541\u001b[0m       0.9592        0.3547  0.1678\n",
      "     14        \u001b[36m0.3533\u001b[0m       0.9592        \u001b[35m0.3542\u001b[0m  0.1666\n",
      "     15        0.3534       0.9603        \u001b[35m0.3535\u001b[0m  0.1661\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5585\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.4181\u001b[0m  0.1664\n",
      "      2        \u001b[36m0.3855\u001b[0m       \u001b[32m0.9458\u001b[0m        \u001b[35m0.3721\u001b[0m  0.1656\n",
      "      3        \u001b[36m0.3700\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.3657\u001b[0m  0.1674\n",
      "      4        \u001b[36m0.3655\u001b[0m       \u001b[32m0.9541\u001b[0m        \u001b[35m0.3628\u001b[0m  0.1663\n",
      "      5        \u001b[36m0.3624\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.3593\u001b[0m  0.1665\n",
      "      6        \u001b[36m0.3604\u001b[0m       0.9546        \u001b[35m0.3586\u001b[0m  0.1672\n",
      "      7        \u001b[36m0.3592\u001b[0m       \u001b[32m0.9561\u001b[0m        \u001b[35m0.3567\u001b[0m  0.1673\n",
      "      8        \u001b[36m0.3580\u001b[0m       \u001b[32m0.9577\u001b[0m        \u001b[35m0.3554\u001b[0m  0.1674\n",
      "      9        \u001b[36m0.3569\u001b[0m       0.9541        0.3580  0.1689\n",
      "     10        0.3572       0.9577        \u001b[35m0.3548\u001b[0m  0.1668\n",
      "     11        \u001b[36m0.3552\u001b[0m       \u001b[32m0.9587\u001b[0m        \u001b[35m0.3548\u001b[0m  0.1670\n",
      "     12        \u001b[36m0.3547\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.3528\u001b[0m  0.1662\n",
      "     13        \u001b[36m0.3543\u001b[0m       \u001b[32m0.9598\u001b[0m        0.3541  0.1671\n",
      "     14        \u001b[36m0.3533\u001b[0m       0.9582        0.3549  0.1676\n",
      "     15        \u001b[36m0.3528\u001b[0m       \u001b[32m0.9618\u001b[0m        \u001b[35m0.3515\u001b[0m  0.1671\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5749\u001b[0m       \u001b[32m0.9329\u001b[0m        \u001b[35m0.4392\u001b[0m  0.1664\n",
      "      2        \u001b[36m0.3927\u001b[0m       \u001b[32m0.9474\u001b[0m        \u001b[35m0.3752\u001b[0m  0.1667\n",
      "      3        \u001b[36m0.3697\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.3664\u001b[0m  0.1686\n",
      "      4        \u001b[36m0.3649\u001b[0m       \u001b[32m0.9541\u001b[0m        \u001b[35m0.3624\u001b[0m  0.1666\n",
      "      5        \u001b[36m0.3624\u001b[0m       \u001b[32m0.9567\u001b[0m        \u001b[35m0.3596\u001b[0m  0.1676\n",
      "      6        \u001b[36m0.3600\u001b[0m       \u001b[32m0.9577\u001b[0m        \u001b[35m0.3588\u001b[0m  0.1669\n",
      "      7        \u001b[36m0.3584\u001b[0m       \u001b[32m0.9582\u001b[0m        \u001b[35m0.3577\u001b[0m  0.1710\n",
      "      8        \u001b[36m0.3568\u001b[0m       0.9577        \u001b[35m0.3554\u001b[0m  0.1662\n",
      "      9        \u001b[36m0.3558\u001b[0m       \u001b[32m0.9587\u001b[0m        \u001b[35m0.3546\u001b[0m  0.1658\n",
      "     10        \u001b[36m0.3552\u001b[0m       \u001b[32m0.9598\u001b[0m        \u001b[35m0.3539\u001b[0m  0.1659\n",
      "     11        0.3553       0.9587        0.3542  0.1669\n",
      "     12        \u001b[36m0.3542\u001b[0m       0.9567        0.3554  0.2016\n",
      "     13        \u001b[36m0.3541\u001b[0m       0.9587        \u001b[35m0.3535\u001b[0m  0.2014\n",
      "     14        \u001b[36m0.3532\u001b[0m       0.9582        0.3552  0.1666\n",
      "     15        0.3535       0.9587        0.3537  0.1662\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5547\u001b[0m       \u001b[32m0.9458\u001b[0m        \u001b[35m0.4164\u001b[0m  0.1690\n",
      "      2        \u001b[36m0.3849\u001b[0m       \u001b[32m0.9484\u001b[0m        \u001b[35m0.3700\u001b[0m  0.1663\n",
      "      3        \u001b[36m0.3702\u001b[0m       \u001b[32m0.9505\u001b[0m        \u001b[35m0.3642\u001b[0m  0.1755\n",
      "      4        \u001b[36m0.3659\u001b[0m       \u001b[32m0.9541\u001b[0m        \u001b[35m0.3610\u001b[0m  0.1656\n",
      "      5        \u001b[36m0.3641\u001b[0m       \u001b[32m0.9561\u001b[0m        \u001b[35m0.3588\u001b[0m  0.1658\n",
      "      6        \u001b[36m0.3615\u001b[0m       \u001b[32m0.9577\u001b[0m        \u001b[35m0.3573\u001b[0m  0.1661\n",
      "      7        \u001b[36m0.3595\u001b[0m       0.9577        \u001b[35m0.3562\u001b[0m  0.1726\n",
      "      8        \u001b[36m0.3576\u001b[0m       0.9551        0.3590  0.1682\n",
      "      9        \u001b[36m0.3564\u001b[0m       \u001b[32m0.9587\u001b[0m        \u001b[35m0.3550\u001b[0m  0.1711\n",
      "     10        \u001b[36m0.3553\u001b[0m       \u001b[32m0.9608\u001b[0m        \u001b[35m0.3532\u001b[0m  0.1663\n",
      "     11        \u001b[36m0.3543\u001b[0m       \u001b[32m0.9613\u001b[0m        \u001b[35m0.3522\u001b[0m  0.1667\n",
      "     12        \u001b[36m0.3536\u001b[0m       \u001b[32m0.9623\u001b[0m        \u001b[35m0.3516\u001b[0m  0.1670\n",
      "     13        0.3538       0.9608        0.3521  0.1670\n",
      "     14        \u001b[36m0.3529\u001b[0m       \u001b[32m0.9634\u001b[0m        \u001b[35m0.3508\u001b[0m  0.1690\n",
      "     15        \u001b[36m0.3521\u001b[0m       0.9603        0.3541  0.1671\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5287\u001b[0m       \u001b[32m0.9417\u001b[0m        \u001b[35m0.3986\u001b[0m  0.1664\n",
      "      2        \u001b[36m0.3783\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.3725\u001b[0m  0.1668\n",
      "      3        \u001b[36m0.3689\u001b[0m       \u001b[32m0.9499\u001b[0m        \u001b[35m0.3672\u001b[0m  0.1659\n",
      "      4        \u001b[36m0.3652\u001b[0m       \u001b[32m0.9515\u001b[0m        \u001b[35m0.3643\u001b[0m  0.1657\n",
      "      5        \u001b[36m0.3627\u001b[0m       \u001b[32m0.9520\u001b[0m        \u001b[35m0.3626\u001b[0m  0.1669\n",
      "      6        \u001b[36m0.3604\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.3604\u001b[0m  0.1678\n",
      "      7        \u001b[36m0.3588\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.3598\u001b[0m  0.1666\n",
      "      8        \u001b[36m0.3571\u001b[0m       \u001b[32m0.9582\u001b[0m        \u001b[35m0.3569\u001b[0m  0.1665\n",
      "      9        \u001b[36m0.3559\u001b[0m       \u001b[32m0.9587\u001b[0m        \u001b[35m0.3564\u001b[0m  0.1672\n",
      "     10        \u001b[36m0.3550\u001b[0m       \u001b[32m0.9603\u001b[0m        \u001b[35m0.3553\u001b[0m  0.1670\n",
      "     11        \u001b[36m0.3538\u001b[0m       \u001b[32m0.9618\u001b[0m        \u001b[35m0.3545\u001b[0m  0.1662\n",
      "     12        \u001b[36m0.3530\u001b[0m       \u001b[32m0.9623\u001b[0m        \u001b[35m0.3535\u001b[0m  0.1665\n",
      "     13        \u001b[36m0.3526\u001b[0m       0.9587        0.3542  0.1674\n",
      "     14        \u001b[36m0.3522\u001b[0m       \u001b[32m0.9628\u001b[0m        \u001b[35m0.3525\u001b[0m  0.1670\n",
      "     15        \u001b[36m0.3514\u001b[0m       0.9618        \u001b[35m0.3523\u001b[0m  0.1660\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "performance_report(net, X, y, X_test, y_test, y_pred, \"binary_remove_augment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.28      0.43       138\n",
      "           1       0.92      1.00      0.96      1189\n",
      "\n",
      "    accuracy                           0.92      1327\n",
      "   macro avg       0.96      0.64      0.70      1327\n",
      "weighted avg       0.93      0.92      0.90      1327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ca-central-1:310906938811:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
